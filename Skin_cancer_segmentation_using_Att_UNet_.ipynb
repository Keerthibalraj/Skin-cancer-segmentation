{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOhOyfo4xx9yCAIfHKgvZxb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Keerthibalraj/Skin-cancer-segmentation/blob/main/Skin_cancer_segmentation_using_Att_UNet_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cu9V4gi3kOct",
        "outputId": "445f5205-83b2-46de-9982-3fae9fa8d923"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import shuffle\n",
        "H=128\n",
        "W=128\n",
        "def create_dir(path):\n",
        "    if not os.path.exists(path):\n",
        "        os.makedirs(path)"
      ],
      "metadata": {
        "id": "0haL64D_1IZE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def shuffling(x,y):\n",
        "    x,y = shuffle(x,y,random_state=42)\n",
        "    return x,y\n",
        "np.random.seed(42)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)"
      ],
      "metadata": {
        "id": "mjvw_USw1NR5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install the python library"
      ],
      "metadata": {
        "id": "ZAUZjVqipf2e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from glob import glob\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import tensorflow as tf\n",
        "from skimage.color import rgb2gray\n",
        "# from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Model, load_model, save_model\n",
        "from tensorflow.keras.layers import Input, Activation, BatchNormalization, Dropout, Lambda, Conv2D, Conv2DTranspose, MaxPooling2D, concatenate, add\n",
        "from tensorflow.keras.optimizers import Adam, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from sklearn.preprocessing import StandardScaler, normalize\n",
        "#from keras_preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras import Sequential\n",
        "from tensorflow.keras import layers, optimizers\n",
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.initializers import glorot_uniform\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
        "import tensorflow.keras.backend as K\n",
        "from IPython.display import display\n",
        "import skimage.io\n",
        "from skimage import io\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from IPython.display import display"
      ],
      "metadata": {
        "id": "YW-H0Pqhn5f7"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "create_dir('files')\n",
        "batch_size=16\n",
        "lr=1e-4\n",
        "num_epoch=5\n",
        "model_path='/content/drive/MyDrive/kaggle/model_att.h5'\n",
        "csv_path='/content/drive/MyDrive/kaggle/data_att.csv'"
      ],
      "metadata": {
        "id": "IT8bBHCo09cb"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_data(dataset_path,split=0.2):\n",
        "    images=sorted(glob(os.path.join(dataset_path,'images','*.jpg')))\n",
        "    masks=sorted(glob(os.path.join(dataset_path,'masks','*.png')))\n",
        "    test_size=int(len(images)*split)\n",
        "    train_x,valid_x=train_test_split(images,test_size=test_size,random_state=42)\n",
        "    train_y,valid_y=train_test_split(masks,test_size=test_size,random_state=42)\n",
        "    train_x,test_x=train_test_split(train_x,test_size=test_size,random_state=42)\n",
        "    train_y,test_y=train_test_split(train_y,test_size=test_size,random_state=42)\n",
        "    return (train_x,train_y),(valid_x,valid_y),(test_x,test_y)"
      ],
      "metadata": {
        "id": "R6ykuXCy0G_S"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path='/content/drive/MyDrive/kaggle'\n",
        "(train_x,train_y),(valid_x,valid_y),(test_x,test_y)= load_data(dataset_path)"
      ],
      "metadata": {
        "id": "hMMpZlRN0M_x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Normalize images"
      ],
      "metadata": {
        "id": "BkT152Gx50EU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def read_image(path):\n",
        "    path=path.decode()\n",
        "    x=cv2.imread(path,cv2.IMREAD_COLOR)\n",
        "    x=cv2.resize(x,(W,H))\n",
        "    x=x/255.0\n",
        "    x=x.astype(np.float32)\n",
        "    #x=np.expand_dims(x,axis=0)\n",
        "    return x\n",
        "def read_mask(path):\n",
        "    path=path.decode()\n",
        "    x=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
        "    x=cv2.resize(x,(W,H))\n",
        "    x=x/255.0\n",
        "    x=x.astype(np.float32)\n",
        "    X=np.expand_dims(x,axis=-1)\n",
        "    x=np.expand_dims(x,axis=-1)\n",
        "    return x\n",
        "def tf_parse(x,y):\n",
        "    def _parse(x,y):\n",
        "        x=read_image(x)\n",
        "        y=read_mask(y)\n",
        "        return x,y\n",
        "    x,y=tf.numpy_function(_parse,[x,y],[tf.float32,tf.float32])\n",
        "    x.set_shape([H,W,3])\n",
        "    y.set_shape([H,W,1])\n",
        "    return x,y\n",
        "def tf_dataset(X,Y,batch):\n",
        "    dataset=tf.data.Dataset.from_tensor_slices((X,Y))\n",
        "    dataset=dataset.map(tf_parse)\n",
        "    dataset=dataset.batch(batch)\n",
        "    dataset=dataset.prefetch(10)\n",
        "    return dataset"
      ],
      "metadata": {
        "id": "Yv62zV3HqHNi"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset= tf_dataset(train_x,train_y,batch_size)\n",
        "valid_dataset= tf_dataset(valid_x,valid_y,batch_size)"
      ],
      "metadata": {
        "id": "ClmXLGWS4-Zt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_steps=len(train_x)//batch_size\n",
        "valid_steps=len(valid_x)//batch_size\n",
        "if len(train_x)%batch_size!=0:\n",
        "    train_steps+=1\n",
        "if len(valid_x)%batch_size!=0:\n",
        "    valid_steps+=1\n",
        "print(train_steps)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2bgRXKpC1pnc",
        "outputId": "15dce5f7-7c5e-49bd-bf0c-09885bf85cca"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "376\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sanity check"
      ],
      "metadata": {
        "id": "s-xd7tv-52bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Attention U-Net model"
      ],
      "metadata": {
        "id": "oZg5bmon8alh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(x)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding=\"same\")(conv)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation(\"relu\")(conv)\n",
        "\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "\n",
        "    return conv\n",
        "\n",
        "\n",
        "def repeat_elem(tensor, rep):\n",
        "    # lambda function to repeat Repeats the elements of a tensor along an axis\n",
        "    #by a factor of rep.\n",
        "    # If tensor has shape (None, 256,256,3), lambda will return a tensor of shape\n",
        "    #(None, 256,256,6), if specified axis=3 and rep=2.\n",
        "\n",
        "     return layers.Lambda(lambda x, repnum: K.repeat_elements(x, repnum, axis=3),\n",
        "                          arguments={'repnum': rep})(tensor)\n",
        "\n",
        "\n",
        "def res_conv_block(x, filter_size, size, dropout, batch_norm=False):\n",
        "    '''\n",
        "    Residual convolutional layer.\n",
        "    Two variants....\n",
        "    Either put activation function before the addition with shortcut\n",
        "    or after the addition (which would be as proposed in the original resNet).\n",
        "\n",
        "    1. conv - BN - Activation - conv - BN - Activation\n",
        "                                          - shortcut  - BN - shortcut+BN\n",
        "\n",
        "    2. conv - BN - Activation - conv - BN\n",
        "                                     - shortcut  - BN - shortcut+BN - Activation\n",
        "\n",
        "    Check fig 4 in https://arxiv.org/ftp/arxiv/papers/1802/1802.06955.pdf\n",
        "    '''\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(x)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    conv = layers.Activation('relu')(conv)\n",
        "\n",
        "    conv = layers.Conv2D(size, (filter_size, filter_size), padding='same')(conv)\n",
        "    if batch_norm is True:\n",
        "        conv = layers.BatchNormalization(axis=3)(conv)\n",
        "    #conv = layers.Activation('relu')(conv)    #Activation before addition with shortcut\n",
        "    if dropout > 0:\n",
        "        conv = layers.Dropout(dropout)(conv)\n",
        "\n",
        "    shortcut = layers.Conv2D(size, kernel_size=(1, 1), padding='same')(x)\n",
        "    if batch_norm is True:\n",
        "        shortcut = layers.BatchNormalization(axis=3)(shortcut)\n",
        "\n",
        "    res_path = layers.add([shortcut, conv])\n",
        "    res_path = layers.Activation('relu')(res_path)    #Activation after addition with shortcut (Original residual block)\n",
        "    return res_path\n",
        "\n",
        "def gating_signal(input, out_size, batch_norm=False):\n",
        "    \"\"\"\n",
        "    resize the down layer feature map into the same dimension as the up layer feature map\n",
        "    using 1x1 conv\n",
        "    :return: the gating feature map with the same dimension of the up layer feature map\n",
        "    \"\"\"\n",
        "    x = layers.Conv2D(out_size, (1, 1), padding='same')(input)\n",
        "    if batch_norm:\n",
        "        x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "def attention_block(x, gating, inter_shape):\n",
        "    shape_x = K.int_shape(x)\n",
        "    shape_g = K.int_shape(gating)\n",
        "\n",
        "# Getting the x signal to the same shape as the gating signal\n",
        "    theta_x = layers.Conv2D(inter_shape, (2, 2), strides=(2, 2), padding='same')(x)  # 16\n",
        "    shape_theta_x = K.int_shape(theta_x)\n",
        "\n",
        "# Getting the gating signal to the same number of filters as the inter_shape\n",
        "    phi_g = layers.Conv2D(inter_shape, (1, 1), padding='same')(gating)\n",
        "    upsample_g = layers.Conv2DTranspose(inter_shape, (3, 3),\n",
        "                                 strides=(shape_theta_x[1] // shape_g[1], shape_theta_x[2] // shape_g[2]),\n",
        "                                 padding='same')(phi_g)  # 16\n",
        "\n",
        "    concat_xg = layers.add([upsample_g, theta_x])\n",
        "    act_xg = layers.Activation('relu')(concat_xg)\n",
        "    psi = layers.Conv2D(1, (1, 1), padding='same')(act_xg)\n",
        "    sigmoid_xg = layers.Activation('sigmoid')(psi)\n",
        "    shape_sigmoid = K.int_shape(sigmoid_xg)\n",
        "    upsample_psi = layers.UpSampling2D(size=(shape_x[1] // shape_sigmoid[1], shape_x[2] // shape_sigmoid[2]))(sigmoid_xg)  # 32\n",
        "\n",
        "    upsample_psi = repeat_elem(upsample_psi, shape_x[3])\n",
        "\n",
        "    y = layers.multiply([upsample_psi, x])\n",
        "\n",
        "    result = layers.Conv2D(shape_x[3], (1, 1), padding='same')(y)\n",
        "    result_bn = layers.BatchNormalization()(result)\n",
        "    return result_bn\n"
      ],
      "metadata": {
        "id": "z17JlnYhrC36"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Attention_UNet(input_shape, NUM_CLASSES=1, dropout_rate=0.0, batch_norm=True):\n",
        "    '''\n",
        "    Attention UNet,\n",
        "\n",
        "    '''\n",
        "    # network structure\n",
        "    FILTER_NUM = 64 # number of basic filters for the first layer\n",
        "    FILTER_SIZE = 3 # size of the convolutional filter\n",
        "    UP_SAMP_SIZE = 2 # size of upsampling filters\n",
        "\n",
        "    inputs = layers.Input(input_shape, dtype=tf.float32)\n",
        "\n",
        "    # Downsampling layers\n",
        "    # DownRes 1, convolution + pooling\n",
        "    conv_128 = conv_block(inputs, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_64 = layers.MaxPooling2D(pool_size=(2,2))(conv_128)\n",
        "    # DownRes 2\n",
        "    conv_64 = conv_block(pool_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_32 = layers.MaxPooling2D(pool_size=(2,2))(conv_64)\n",
        "    # DownRes 3\n",
        "    conv_32 = conv_block(pool_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_16 = layers.MaxPooling2D(pool_size=(2,2))(conv_32)\n",
        "    # DownRes 4\n",
        "    conv_16 = conv_block(pool_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    pool_8 = layers.MaxPooling2D(pool_size=(2,2))(conv_16)\n",
        "    # DownRes 5, convolution only\n",
        "    conv_8 = conv_block(pool_8, FILTER_SIZE, 16*FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # Upsampling layers\n",
        "    # UpRes 6, attention gated concatenation + upsampling + double residual convolution\n",
        "    gating_16 = gating_signal(conv_8, 8*FILTER_NUM, batch_norm)\n",
        "    att_16 = attention_block(conv_16, gating_16, 8*FILTER_NUM)\n",
        "    up_16 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(conv_8)\n",
        "    up_16 = layers.concatenate([up_16, att_16], axis=3)\n",
        "    up_conv_16 = conv_block(up_16, FILTER_SIZE, 8*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 7\n",
        "    gating_32 = gating_signal(up_conv_16, 4*FILTER_NUM, batch_norm)\n",
        "    att_32 = attention_block(conv_32, gating_32, 4*FILTER_NUM)\n",
        "    up_32 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_16)\n",
        "    up_32 = layers.concatenate([up_32, att_32], axis=3)\n",
        "    up_conv_32 = conv_block(up_32, FILTER_SIZE, 4*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 8\n",
        "    gating_64 = gating_signal(up_conv_32, 2*FILTER_NUM, batch_norm)\n",
        "    att_64 = attention_block(conv_64, gating_64, 2*FILTER_NUM)\n",
        "    up_64 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_32)\n",
        "    up_64 = layers.concatenate([up_64, att_64], axis=3)\n",
        "    up_conv_64 = conv_block(up_64, FILTER_SIZE, 2*FILTER_NUM, dropout_rate, batch_norm)\n",
        "    # UpRes 9\n",
        "    gating_128 = gating_signal(up_conv_64, FILTER_NUM, batch_norm)\n",
        "    att_128 = attention_block(conv_128, gating_128, FILTER_NUM)\n",
        "    up_128 = layers.UpSampling2D(size=(UP_SAMP_SIZE, UP_SAMP_SIZE), data_format=\"channels_last\")(up_conv_64)\n",
        "    up_128 = layers.concatenate([up_128, att_128], axis=3)\n",
        "    up_conv_128 = conv_block(up_128, FILTER_SIZE, FILTER_NUM, dropout_rate, batch_norm)\n",
        "\n",
        "    # 1*1 convolutional layers\n",
        "    conv_final = layers.Conv2D(NUM_CLASSES, kernel_size=(1,1))(up_conv_128)\n",
        "    conv_final = layers.BatchNormalization(axis=3)(conv_final)\n",
        "    conv_final = layers.Activation('sigmoid')(conv_final)  #Change to softmax for multichannel\n",
        "\n",
        "    # Model integration\n",
        "    model =Model(inputs, conv_final, name=\"Attention_UNet\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "PrAaY11inULT"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "def iou(y_true, y_pred):\n",
        "    def f(y_true, y_pred):\n",
        "        intersection = (y_true * y_pred).sum()\n",
        "        union = y_true.sum() + y_pred.sum() - intersection\n",
        "        x = (intersection + 1e-15) / (union + 1e-15)\n",
        "        x = x.astype(np.float32)\n",
        "        return x\n",
        "    return tf.numpy_function(f, [y_true, y_pred], tf.float32)\n",
        "\n",
        "smooth = 1e-15\n",
        "def dice_coef(y_true, y_pred):\n",
        "    y_true = tf.keras.layers.Flatten()(y_true)\n",
        "    y_pred = tf.keras.layers.Flatten()(y_pred)\n",
        "    intersection = tf.reduce_sum(y_true * y_pred)\n",
        "    return (2. * intersection + smooth) / (tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) + smooth)\n",
        "\n",
        "def dice_loss(y_true, y_pred):\n",
        "    return 1.0 - dice_coef(y_true, y_pred)"
      ],
      "metadata": {
        "id": "rP9RiWv58Ygm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import Recall, Precision\n"
      ],
      "metadata": {
        "id": "ZhGcDco_2GVB"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_HEIGHT = 128\n",
        "IMG_WIDTH  = 128\n",
        "IMG_CHANNELS = 3\n",
        "num_labels = 1  #Binary\n",
        "input_shape = (IMG_HEIGHT,IMG_WIDTH,IMG_CHANNELS)\n",
        "batch_size = 8\n",
        "att_unet_model = Attention_UNet(input_shape)\n",
        "\n",
        "att_unet_model.compile(optimizer=Adam(lr = 1e-2), loss='binary_crossentropy',             metrics=['accuracy', dice_coef, iou])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PEt1Wzy2JqJ",
        "outputId": "68caa029-7537-420f-ac1a-6ad7c4e699f3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "callbacks=[\n",
        "    ModelCheckpoint(model_path,verbose=1,save_best_only=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss',factor=0.1,patience=5, min_lr=1e-7, verbose=1),\n",
        "    CSVLogger(csv_path),\n",
        "    TensorBoard(),\n",
        "    EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=False)\n",
        "]"
      ],
      "metadata": {
        "id": "fv2dBklb2qAJ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "att_unet_model.fit(\n",
        "        train_dataset,\n",
        "        epochs=num_epoch,\n",
        "        validation_data=valid_dataset,\n",
        "        steps_per_epoch=train_steps,\n",
        "        validation_steps=valid_steps,\n",
        "        callbacks=callbacks\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C_Tnxx-32utp",
        "outputId": "1e818b8b-5cf2-475b-f45a-243474bc3818"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "261/376 [===================>..........] - ETA: 1:03:13 - loss: 0.4114 - accuracy: 0.8992 - dice_coef: 0.5580 - iou: 0.3886"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('fivethirtyeight')\n",
        "plt.figure(figsize=(10,20))\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(att_unet_model.history.history['loss'], 'b-', label='train_loss')\n",
        "plt.plot(att_unet_model.history.history['val_loss'], 'r-', label='val_loss')\n",
        "plt.legend(loc='best')\n",
        "plt.xlabel('epoch')\n",
        "plt.title('Loss')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "11rjpa7v2z1o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "import numpy as np\n",
        "import cv2\n",
        "import pandas as pd\n",
        "from glob import glob\n",
        "from tqdm import tqdm\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.utils import CustomObjectScope\n",
        "from sklearn.metrics import accuracy_score, f1_score, jaccard_score, precision_score, recall_score\n",
        "\n",
        "\n",
        "H = 128\n",
        "W = 128\n",
        "\n",
        "def read_image1(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_COLOR)\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.float32)\n",
        "    x = np.expand_dims(x, axis=0)\n",
        "    return ori_x, x\n",
        "\n",
        "def read_mask1(path):\n",
        "    x = cv2.imread(path, cv2.IMREAD_GRAYSCALE)\n",
        "    x = cv2.resize(x, (W, H))\n",
        "    ori_x = x\n",
        "    x = x/255.0\n",
        "    x = x.astype(np.int32)\n",
        "    return ori_x, x\n",
        "\n",
        "def save_results(ori_x, ori_y, y_pred, save_image_path):\n",
        "    line = np.ones((H, 10, 3)) * 255\n",
        "\n",
        "    ori_y = np.expand_dims(ori_y, axis=-1)\n",
        "    ori_y = np.concatenate([ori_y, ori_y, ori_y], axis=-1)\n",
        "\n",
        "    y_pred = np.expand_dims(y_pred, axis=-1)\n",
        "    y_pred = np.concatenate([y_pred, y_pred, y_pred], axis=-1)\n",
        "\n",
        "    cat_images = np.concatenate([ori_x, line, ori_y, line, y_pred*255], axis=1)\n",
        "    cv2.imwrite(save_image_path, cat_images)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    np.random.seed(42)\n",
        "    tf.random.set_seed(42)\n",
        "\n",
        "\n",
        "    create_dir(\"results\")\n",
        "    with CustomObjectScope({'iou': iou, 'dice_coef': dice_coef}):\n",
        "        model = tf.keras.models.load_model(\"/content/drive/MyDrive/kaggle/model_att.h5\")\n",
        "\n",
        "\n",
        "\n",
        "    SCORE = []\n",
        "    for x, y in tqdm(zip(test_x, test_y), total=len(test_x)):\n",
        "        \"\"\" Exctracting the image name \"\"\"\n",
        "        import warnings\n",
        "        warnings.filterwarnings('always')\n",
        "        name = x.split(\"/\")[-1]\n",
        "\n",
        "        \"\"\" Read the image and mask \"\"\"\n",
        "        ori_x, x = read_image1(x)\n",
        "        ori_y, y = read_mask1(y)\n",
        "\n",
        "        \"\"\" Predicting the mask \"\"\"\n",
        "        y_pred = model.predict(x)[0] > 0.5\n",
        "        y_pred = np.squeeze(y_pred, axis=-1)\n",
        "        y_pred = y_pred.astype(np.int32)\n",
        "\n",
        "        \"\"\" Saving the predicted mask \"\"\"\n",
        "        save_image_path = f\"results/{name}\"\n",
        "        save_results(ori_x, ori_y, y_pred, save_image_path)\n",
        "\n",
        "        \"\"\" Flattening the array \"\"\"\n",
        "        y = y.flatten()\n",
        "        y_pred = y_pred.flatten()\n",
        "\n",
        "        \"\"\" Calculating metrics values \"\"\"\n",
        "        acc_value = accuracy_score(y, y_pred)\n",
        "        f1_value = f1_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        jac_value = jaccard_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        recall_value = recall_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        precision_value = precision_score(y, y_pred, labels=[0, 1], average=\"binary\")\n",
        "        SCORE.append([name, acc_value, f1_value, jac_value, recall_value, precision_value])\n",
        "\n",
        "    \"\"\" mean metrics values \"\"\"\n",
        "    score = [s[1:] for s in SCORE]\n",
        "    score = np.mean(score, axis=0)\n",
        "    print(f\"Accuracy: {score[0]:0.5f}\")\n",
        "    print(f\"F1: {score[1]:0.5f}\")\n",
        "    print(f\"Jaccard: {score[2]:0.5f}\")\n",
        "    print(f\"Recall: {score[3]:0.5f}\")\n",
        "    print(f\"Precision: {score[4]:0.5f}\")\n",
        "\n",
        "    df = pd.DataFrame(SCORE, columns = [\"Image Name\", \"Acc\", \"F1\", \"Jaccard\", \"Recall\", \"Precision\"])\n",
        "    df.to_csv(\"/content/drive/MyDrive/kaggle/Output_att.csv\")"
      ],
      "metadata": {
        "id": "ijsCDNDx3NHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "x9tOvM7570C3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}